<!--t Computer Geeks: an Endangered Species? t-->
<!--tag 2012,archive,culture,features,thinkboxly tag-->
  
There was once a time when if you really wanted to work with computers, you had to build your own hardware. You had to work programming languages in to existing hardware yourself. In either case, you knew your hardware and software alike quite well and were completely comfortable and capable messing around with both. Even as the decades wore on and software became more complex as hardware became simpler, anyone worth their geek salt was expected to have a decent working knowledge of current releases in both categories and be able to hold his own in dealing with them.  
  
However, recent years have seen a major shift in this trend, and signs point to things only getting much worse. Are we arriving at the final days of true computer geeks?  
  

## The Cause

  
Now I know what you’re probably thinking: “What? There are dozens of new geeks created every day! They aren’t going extinct!” Well, if you were to survey people about if they call themselves geeks or not, you’d probably get a fair amount of data supporting that statement. However if you were to actually test these self-ordained geeks on their abilities, what you would find today would tell a vastly different story than what you’d find even just a decade ago.  
  
Few things go extinct on the basis of their own activity. On their own inactivity perhaps, but as dedicated computer wizards are anything but inactive in regards to technology, it must be an external factor that is causing the decrease in the number of people truly worthy of geekdom. Those factors challenge the true geek from both sides of the computer world. Here are my top two.  
  

#### The Shrinking of Hardware

  
Computers were created for convenience. I get that. So it was not very convenient for early computers to occupy whole rooms just to do basic calculations. But then the personal computer came along and shrunk things down to where any adult could easily carry an entire computer by themselves. Laptops served to further compact the components of a traditional PC. But then…then ultrabooks came along. Tablets came along. The difference with these? Unlike the personal computer, they didn’t improve customizability over previous generation computers. Instead, they did away with it completely, and continue to do so in new ways. Why? Just so that the hardware can be smaller. Not more convenient, but smaller. ‘Convenient’ would mean the user has full access to the hardware and to adjust or replace it as he likes, but as time goes on, it’s getting harder and harder to find computers that allow this sort of freedom, and in sacrificing freedom, manufacturers are sacrificing the ability for people to get to know their hardware really well. And besides, who needs to know specs when every computer is built with proprietary hardware designed to feel like every other tiny set of proprietary hardware on the market?  
  
I wish I could say the answer to that question is Gamers, but unfortunately I fear that before long even they won’t have a care. There was a time when if you didn’t know how to install a 3D Accelerator to supplement your 2D video card, you could just stick to playing Unreal in 320×240 software mode, thank you very much. Even today, PC Gamers are the driving force behind completely custom built machines, but with the number of AAA titles for PC in decline, who can say how long it will be before the remainders of the PC gaming community make the switch to prebuilt consoles? As many if you saw, even I recently made the jump to console gaming, and I have to admit, what software my PS3 offers is a lot more enticing than what new software is being developed for PCs right now, despite the fact that my custom PC has far more horsepower and churns out nicer graphics.  
  
And that brings me right into my second point (see what I did there?):  
  

#### The Streamlining/Optimization of Software

  
Now don’t get me wrong: on its own, software optimization is a very good thing. The problem is, it is simply unreasonable to expect most companies to put the time and resources into optimizing one piece of software for a thousand different possible hardware configurations. In turn, the general population of today has come to rely more on software optimization than good hardware, the end result being that freedom has been sacrificed in the name of the actual computer experience as well as the physical makeup of the computer itself.  
  
To continue on the gaming note, there is perhaps no better example of what optimization can do for software than taking a look at console games. Just look at the special effects in games like Final Fantasy XII for the Playstation 2 and you’ll see what I mean. To put things in perspective, the console’s hardware is somewhat akin to the average Windows 98 machine of yesteryear. Yet somehow developers were able to pull off motion blur, light blooming, distortion, reflections, and a host of other effects typically thought of as being exclusively next-gen. How did they do this? By working on only one set of hardware and taking full advantage of every possible trick that hardware was capable of…without having to worry about all those tricks not functioning properly in other configurations. Indeed, the effects were tricks themselves and not ‘true’ effects like what we see today; they were only made possible by exploiting the unique functions of the PS2 hardware and would either look bad, run slow, or outright not function on any other setup of the day without serious modification.  
  
That’s the power of optimization, and it sounds good to developers who only have to learn one set of hardware, and to consumers who want high performance at low cost. The unfortunate side effect is, however, that everyone is left with a linear experience. Your experience is the same as the next guy; never mind, for example, that you’ve got the newer PS3 Slim and he’s only got the old, fat PS3. There’s no advantage to having better hardware in this scenario, and absolutely no computer knowledge is required in order to get the best experience available.  
  
In short, as optimization of software for prebuilt sets of hardware increases, the popularity of prebuilt sets of hardware likewise increases, and then the benefits of being a geek take a nosedive. And without those benefits, who will aspire to learn computers well? As you can see, it’s seemingly a downward spiral to extermination.  
  

## The Effect

  
…however, that is the worst-case scenario. There’s one small detail in all this that may just change everything. The fact is, as long as hardware and software remain in production, one thing is for certain: there will be groups of people that know them well enough to keep making new developments in both arenas.  
  
In that regard, true computer geeks aren’t going anywhere anytime soon.  
  
What does remain to be seen is whether or not the changes that continue to force their way into the computer industry will strike a blow against the number of average people that learn the ins and outs of computers by tinkering with them from a young age. There’s no reason that the computers of tomorrow can’t be as open as the computers of today or even moreso, but if mainstream products are to be this open, significant changes will have to take place in the direction developers seem to be heading. It is likely that there will always be some form of open computing community (yay, Linux!) but otherwise it may well end up that one day a person is considered a geek if he knows a bit of HTML. That will mean a lot of self-proclaimed geeks–far more geeks than we have today–yet few with deep knowledge.  
  
Thankfully, not everyone is joining in on the closed hardware/software bandwagon, with projects like the [Raspberry Pi $25 computer](http://www.raspberrypi.org/) introducing advanced computing to young people at an affordable cost of entry. If received well, the Pi and similar projects could easily create an entirely new industry paradigm of cheap experimental computers capable of handling the serious geek tasks that less open sets of prebuilt hardware cannot, actually starting a revolution for geekdom despite the changing times.  
  
On the other hand, should experimental computers fail to catch on with their younger target audience, it may well be only a matter of time before the general population ceases to care how their computers run.  
  
Either way, strap yourselves in, fellow geeks! We live in interesting times.
